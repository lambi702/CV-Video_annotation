{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet50, ResNet50_Weights, vgg16,VGG16_Weights\n",
    "import pickle \n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the list of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "files = os.listdir(data_path+'droplets/')\n",
    "files = [f.split(\".\")[0] for f in files]\n",
    "files = list(set(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file):\n",
    "    return np.array(cv2.imreadmulti(file, flags=cv2.IMREAD_GRAYSCALE)[1], dtype=object)\n",
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellsDataset(Dataset):\n",
    "    def __init__(self, files, data_path, transform=None, seed = 42, test_size = 0.2):\n",
    "        self.files = files\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.seed = seed\n",
    "        self.test_size = test_size\n",
    "        self.images = []\n",
    "        temp = [load_json(data_path+'generated/'+ f+'.json') for f in files]\n",
    "        self.data = []\n",
    "        for t, file in zip(temp, files):\n",
    "            images = load_images(data_path+'droplets/' + file +'.tif')\n",
    "            for i in range(len(t['valid_bb'])):\n",
    "                if t['valid_bb'][i] == 0 or len(t['cell'][i]) > 200:\n",
    "                    continue\n",
    "                self.images.append(images[i])\n",
    "                t['cell'][i] = t['cell'][i] + [[-1,-1]] * (200 - len(t['cell'][i]))\n",
    "                self.data.append({'frame': t['file_name'], 'bb': t['bb'][i], 'cell': t['cell'][i]})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        data = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {'frame': data['frame'], 'image': image, 'bb': data['bb'], 'cell': data['cell']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = CellsDataset(files, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
